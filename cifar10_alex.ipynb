{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 149677,
     "status": "ok",
     "timestamp": 1594026737917,
     "user": {
      "displayName": "yimign zhang",
      "photoUrl": "",
      "userId": "15825212196047040768"
     },
     "user_tz": -480
    },
    "id": "FJWQ3daBNakM",
    "outputId": "6781a157-e302-49bf-bbba-1c16f7760f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "using  SGD\n",
      "Epoch: 1 Training...\n",
      "epoch: 1\t batch: 1000\t loss: 2.302804\n",
      "Accuracy of the network on the 10000 test images: 9 %\n",
      "Epoch: 2 Training...\n",
      "epoch: 2\t batch: 1000\t loss: 2.301773\n",
      "Accuracy of the network on the 10000 test images: 12 %\n",
      "Epoch: 3 Training...\n",
      "epoch: 3\t batch: 1000\t loss: 2.299185\n",
      "Accuracy of the network on the 10000 test images: 16 %\n",
      "Epoch: 4 Training...\n",
      "epoch: 4\t batch: 1000\t loss: 2.224931\n",
      "Accuracy of the network on the 10000 test images: 20 %\n",
      "Epoch: 5 Training...\n",
      "epoch: 5\t batch: 1000\t loss: 1.892978\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "Epoch: 6 Training...\n",
      "epoch: 6\t batch: 1000\t loss: 1.687035\n",
      "Accuracy of the network on the 10000 test images: 40 %\n",
      "Epoch: 7 Training...\n",
      "epoch: 7\t batch: 1000\t loss: 1.543230\n",
      "Accuracy of the network on the 10000 test images: 41 %\n",
      "Epoch: 8 Training...\n",
      "epoch: 8\t batch: 1000\t loss: 1.431123\n",
      "Accuracy of the network on the 10000 test images: 49 %\n",
      "Epoch: 9 Training...\n",
      "epoch: 9\t batch: 1000\t loss: 1.347802\n",
      "Accuracy of the network on the 10000 test images: 51 %\n",
      "Epoch: 10 Training...\n",
      "epoch: 10\t batch: 1000\t loss: 1.277665\n",
      "Accuracy of the network on the 10000 test images: 55 %\n",
      "Epoch: 11 Training...\n",
      "epoch: 11\t batch: 1000\t loss: 1.198035\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "Epoch: 12 Training...\n",
      "epoch: 12\t batch: 1000\t loss: 1.151210\n",
      "Accuracy of the network on the 10000 test images: 57 %\n",
      "Epoch: 13 Training...\n",
      "epoch: 13\t batch: 1000\t loss: 1.084931\n",
      "Accuracy of the network on the 10000 test images: 61 %\n",
      "Epoch: 14 Training...\n",
      "epoch: 14\t batch: 1000\t loss: 1.030332\n",
      "Accuracy of the network on the 10000 test images: 62 %\n",
      "Epoch: 15 Training...\n",
      "epoch: 15\t batch: 1000\t loss: 0.988549\n",
      "Accuracy of the network on the 10000 test images: 62 %\n",
      "Epoch: 16 Training...\n",
      "epoch: 16\t batch: 1000\t loss: 0.942455\n",
      "Accuracy of the network on the 10000 test images: 63 %\n",
      "using  Momentum\n",
      "Epoch: 1 Training...\n",
      "epoch: 1\t batch: 1000\t loss: 2.302735\n",
      "Accuracy of the network on the 10000 test images: 10 %\n",
      "Epoch: 2 Training...\n",
      "epoch: 2\t batch: 1000\t loss: 1.895485\n",
      "Accuracy of the network on the 10000 test images: 36 %\n",
      "Epoch: 3 Training...\n",
      "epoch: 3\t batch: 1000\t loss: 1.486303\n",
      "Accuracy of the network on the 10000 test images: 46 %\n",
      "Epoch: 4 Training...\n",
      "epoch: 4\t batch: 1000\t loss: 1.275660\n",
      "Accuracy of the network on the 10000 test images: 55 %\n",
      "Epoch: 5 Training...\n",
      "epoch: 5\t batch: 1000\t loss: 1.126848\n",
      "Accuracy of the network on the 10000 test images: 58 %\n",
      "Epoch: 6 Training...\n",
      "epoch: 6\t batch: 1000\t loss: 1.033560\n",
      "Accuracy of the network on the 10000 test images: 61 %\n",
      "Epoch: 7 Training...\n",
      "epoch: 7\t batch: 1000\t loss: 0.946751\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "Epoch: 8 Training...\n",
      "epoch: 8\t batch: 1000\t loss: 0.886875\n",
      "Accuracy of the network on the 10000 test images: 63 %\n",
      "Epoch: 9 Training...\n",
      "epoch: 9\t batch: 1000\t loss: 0.835829\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "Epoch: 10 Training...\n",
      "epoch: 10\t batch: 1000\t loss: 0.797385\n",
      "Accuracy of the network on the 10000 test images: 66 %\n",
      "Epoch: 11 Training...\n",
      "epoch: 11\t batch: 1000\t loss: 0.752864\n",
      "Accuracy of the network on the 10000 test images: 66 %\n",
      "Epoch: 12 Training...\n",
      "epoch: 12\t batch: 1000\t loss: 0.717083\n",
      "Accuracy of the network on the 10000 test images: 67 %\n",
      "Epoch: 13 Training...\n",
      "epoch: 13\t batch: 1000\t loss: 0.683338\n",
      "Accuracy of the network on the 10000 test images: 66 %\n",
      "Epoch: 14 Training...\n",
      "epoch: 14\t batch: 1000\t loss: 0.654858\n",
      "Accuracy of the network on the 10000 test images: 66 %\n",
      "Epoch: 15 Training...\n",
      "epoch: 15\t batch: 1000\t loss: 0.634115\n",
      "Accuracy of the network on the 10000 test images: 67 %\n",
      "Epoch: 16 Training...\n",
      "epoch: 16\t batch: 1000\t loss: 0.605843\n",
      "Accuracy of the network on the 10000 test images: 67 %\n",
      "using  RMSprop\n",
      "Epoch: 1 Training...\n",
      "epoch: 1\t batch: 1000\t loss: 1.806773\n",
      "Accuracy of the network on the 10000 test images: 39 %\n",
      "Epoch: 2 Training...\n",
      "epoch: 2\t batch: 1000\t loss: 1.365920\n",
      "Accuracy of the network on the 10000 test images: 52 %\n",
      "Epoch: 3 Training...\n",
      "epoch: 3\t batch: 1000\t loss: 1.179636\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "Epoch: 4 Training...\n",
      "epoch: 4\t batch: 1000\t loss: 1.052460\n",
      "Accuracy of the network on the 10000 test images: 60 %\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义超参数\n",
    "BATCH_SIZE = 32\n",
    "nEpochs = 16\n",
    "numPrint = 1000\n",
    "\n",
    "# cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])])\n",
    "\n",
    "# 加载数据集 (训练集和测试集)\n",
    "trainset = torchvision.datasets.CIFAR10(root='./', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# 定义神经网络\n",
    "class AlexNet(nn.Module):  # 训练 ALexNet\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        # 五个卷积层\n",
    "        self.conv1 = nn.Sequential(  # 输入 32 * 32 * 3\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=1),  # (32-3+2)/1+1 = 32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # (32-2)/2+1 = 16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(  # 输入 16 * 16 * 6\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1, padding=1),  # (16-3+2)/1+1 = 16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # (16-2)/2+1 = 8\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(  # 输入 8 * 8 * 16\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),  # (8-3+2)/1+1 = 8\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # (8-2)/2+1 = 4\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(  # 输入 4 * 4 * 64\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),  # (4-3+2)/1+1 = 4\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # (4-2)/2+1 = 2\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(  # 输入 2 * 2 * 128\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),  # (2-3+2)/1+1 = 2\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # (2-2)/2+1 = 1\n",
    "        )  # 最后一层卷积层，输出 1 * 1 * 128\n",
    "        # 全连接层\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(128, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 为每个优化器创建一个Net\n",
    "net_SGD = AlexNet()\n",
    "net_Momentum = AlexNet()\n",
    "net_RMSprop = AlexNet()\n",
    "net_Adam = AlexNet()\n",
    "net_Adagrad = AlexNet()\n",
    "net_Adadelta = AlexNet()\n",
    "nets = [net_SGD, net_Momentum, net_RMSprop, net_Adam, net_Adagrad, net_Adadelta]\n",
    "\n",
    "# 初始化优化器\n",
    "opt_SGD = torch.optim.SGD(net_SGD.parameters(), lr=0.01)\n",
    "opt_Momentum = torch.optim.SGD(net_Momentum.parameters(), lr=0.01, momentum=0.8)\n",
    "opt_RMSprop = torch.optim.RMSprop(net_RMSprop.parameters(), lr=0.001, alpha=0.99)\n",
    "opt_Adam = torch.optim.Adam(net_Adam.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
    "opt_Adagrad = torch.optim.Adagrad(net_Adagrad.parameters(), lr=0.01)\n",
    "opt_Adadelta = torch.optim.Adadelta(net_Adadelta.parameters(), lr=0.01)\n",
    "\n",
    "optimizers = [opt_SGD, opt_Momentum, opt_RMSprop, opt_Adam, opt_Adagrad, opt_Adadelta]\n",
    "\n",
    "# 定义损失函数\n",
    "loss_function = nn.CrossEntropyLoss()  # 交叉熵损失\n",
    "\n",
    "# 记录training时不同神经网络的loss值\n",
    "losses_history = [[], [], [], [], [], []]\n",
    "\n",
    "# 记录training时不同神经网络的top1Acc值\n",
    "top1Acc_history = [[], [], [], [], [], []]\n",
    "\n",
    "\n",
    "# 使用测试数据测试网络\n",
    "def Accuracy():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # 训练集中不需要反向传播\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)  # 将输入和目标在每一步都送入GPU\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 返回每一行中最大值的那个元素，且返回其索引\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "\n",
    "optime = ['SGD', 'Momentum', 'RMSprop', 'Adam', 'Adagrad', 'Adadelta']\n",
    "name_indx = 0\n",
    "for net, opt, l_his, acc_his in zip(nets, optimizers, losses_history, top1Acc_history):\n",
    "    print('using ', optime[name_indx])\n",
    "    for epoch in range(nEpochs):\n",
    "        running_loss = 0.0\n",
    "        print('Epoch:', epoch + 1, 'Training...')\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data  # 取数据\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # 将输入和目标在每一步都送入GPU\n",
    "            opt.zero_grad()  # 将梯度置零\n",
    "            # 训练\n",
    "            net = net.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_function(outputs, labels).to(device)\n",
    "\n",
    "            loss.backward()  # 反向传播\n",
    "            opt.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % numPrint == 999:  # 每 numPrint 张图片，打印一次\n",
    "                l_his.append(running_loss / numPrint)\n",
    "                print('epoch: %d\\t batch: %d\\t loss: %.6f' % (epoch + 1, i + 1, running_loss / numPrint))\n",
    "                running_loss = 0.0\n",
    "                top1Acc = Accuracy()\n",
    "                print('Accuracy of the network on the 10000 test images: %d %%' % top1Acc)\n",
    "                acc_his.append(top1Acc)\n",
    "    model_name = optime[name_indx] + '_model.pkl'\n",
    "    save_path = './' + model_name\n",
    "    torch.save(net, save_path)\n",
    "    name_indx += 1\n",
    "\n",
    "for i, l_his in enumerate(losses_history):\n",
    "    plt.plot(l_his, label=optime[i])\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim((0, 3))\n",
    "plt.show()\n",
    "\n",
    "for i, t_his in enumerate(top1Acc_history):\n",
    "    plt.plot(t_his, label=optime[i])\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Top1Acc')\n",
    "plt.ylim((0, 100))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8s0mEKjl2Wml"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNg/EPGgM6CnKPyPep48Jb+",
   "collapsed_sections": [],
   "name": "cifar10_alex_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
