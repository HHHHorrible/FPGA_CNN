{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # conv1, 加padding扩充成32*32\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        # conv2\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "    \n",
    "        # fc\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # conv --> relu --> maxpool\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        # num_flat_feaures = 16*16*5\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        # fc1 \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size torch.Size([60000, 28, 28])\n",
      "train label size torch.Size([60000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "EPOCH = 10               # 训练epoch次数\n",
    "BATCH_SIZE = 64          # 批训练的数量\n",
    "LR = 0.001               # 学习率      \n",
    "\n",
    "train_data = datasets.MNIST(root='./mnist/', train=True,transform=transforms.ToTensor(), download=True)\n",
    "test_data = datasets.MNIST(root='./mnist/', train=False,transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "test_x = test_data.test_data.type(torch.FloatTensor)[:2000]/255\n",
    "test_y = test_data.test_labels.numpy()[:2000]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"train size\", train_data.train_data.size())\n",
    "print(\"train label size\", train_data.train_labels.size())\n",
    "\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 loss:0.0306%\n",
      "epoch2 loss:0.0362%\n",
      "epoch3 loss:0.0569%\n",
      "epoch4 loss:0.1371%\n",
      "epoch5 loss:0.0015%\n",
      "epoch6 loss:0.1058%\n",
      "epoch7 loss:0.0060%\n",
      "epoch8 loss:0.0004%\n",
      "epoch9 loss:0.0466%\n",
      "epoch10 loss:0.0091%\n"
     ]
    }
   ],
   "source": [
    "# 使用dataloader进行分批\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# model\n",
    "model = LeNet5()\n",
    "# loss functino\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# device \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# train\n",
    "for epoch in range(EPOCH):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        # gpu use\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        # loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # zero_grad\n",
    "        optimizer.zero_grad()\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # step 参数更新\n",
    "        optimizer.step()\n",
    "        \n",
    "    # 为什么用item，因为loss只有一个数值\n",
    "    print('epoch{} loss:{:.4f}%'.format(epoch+1, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'get_activation.<locals>.hook'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-8eb61a21463e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 保存模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mnist_lenet5.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mnist_lenet5.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 测试\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m     \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m     \u001b[0mdata_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_buf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'get_activation.<locals>.hook'"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "torch.save(model, 'mnist_lenet5.pt')\n",
    "model = torch.load('mnist_lenet5.pt')\n",
    "\n",
    "# 测试\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# activation = {}\n",
    "# def get_activation(name):\n",
    "#     def hook(model, input, output):\n",
    "#         activation[name] = output.detach()\n",
    "#     return hook\n",
    "\n",
    "# model.fc1.register_forward_hook(get_activation('fc1'))\n",
    "\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # forward\n",
    "    out = model(images)\n",
    "#     # 查看中间层输出\n",
    "#     print((activation['fc1']))\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    total = total + labels.size(0)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    \n",
    "# correct \n",
    "print('10000 test correct:{:.4f}%'.format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.load_state_dict of LeNet5(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n",
      "Parameter containing:\n",
      "tensor([[ 3.3270e-02, -1.7707e-01, -3.9913e-02, -7.7015e-03, -1.4851e-01,\n",
      "          2.5459e-01, -8.6036e-02,  1.4460e-01, -2.9920e-02, -4.5989e-02,\n",
      "         -3.0611e-01,  9.8063e-02,  2.2010e-03,  7.7754e-02,  1.0695e-01,\n",
      "          3.0505e-02, -2.3469e-01, -3.5094e-01, -4.7687e-02, -1.3206e-01,\n",
      "         -2.7678e-01, -1.9024e-01,  1.0222e-01, -1.8522e-02,  5.0097e-02,\n",
      "         -2.0001e-01, -1.3214e-01,  3.0613e-02,  2.8291e-02,  1.7169e-01,\n",
      "          1.3392e-01,  1.4378e-01, -2.1543e-01, -1.0580e-01,  2.5260e-02,\n",
      "         -1.1382e-01, -5.3899e-02,  6.5151e-03,  1.4884e-02,  3.6829e-02,\n",
      "          1.9558e-01, -1.1512e-01,  1.1655e-01, -9.3832e-02, -3.7982e-02,\n",
      "          7.7592e-02, -1.1102e-01,  9.7204e-02, -2.3005e-01,  8.7538e-02,\n",
      "          3.7741e-02, -2.1634e-02,  2.4317e-02, -1.9645e-02,  8.4856e-02,\n",
      "          1.6232e-01, -9.4795e-02,  2.1839e-01, -1.3015e-01, -2.2071e-01,\n",
      "          1.3820e-01, -2.7378e-01,  3.1258e-02,  1.2496e-01, -1.0502e-02,\n",
      "         -1.8505e-01,  1.3080e-01,  1.2665e-01,  4.6746e-02, -1.6723e-01,\n",
      "         -1.5502e-01,  9.7650e-03, -1.8434e-01,  4.6126e-02, -1.1638e-01,\n",
      "          9.3102e-03,  1.5326e-01, -1.2817e-01, -2.1917e-02, -2.1591e-01,\n",
      "         -2.4709e-01, -2.5570e-02, -1.9398e-01, -1.9832e-01],\n",
      "        [-5.9268e-02, -6.1865e-02, -8.6214e-02, -2.2703e-02, -2.2295e-01,\n",
      "         -1.8366e-01,  1.5423e-01,  1.1887e-01,  1.4249e-01, -1.7536e-02,\n",
      "          2.8640e-02, -1.7220e-01, -1.2200e-01,  2.1648e-01,  1.1249e-01,\n",
      "         -1.2815e-01, -2.6565e-01,  1.9241e-01, -1.5273e-01,  5.9724e-02,\n",
      "          8.7900e-02,  1.1731e-01, -3.2088e-01, -2.4050e-01, -1.8368e-02,\n",
      "          1.0796e-01,  9.3408e-02, -3.7540e-02, -1.0161e-01,  1.4058e-01,\n",
      "         -2.2540e-01, -1.2408e-01, -8.3583e-02, -1.1742e-01, -6.6859e-02,\n",
      "          1.3410e-01, -2.5875e-01, -1.0418e-01, -8.7291e-02,  2.0997e-02,\n",
      "          1.7141e-01, -7.3459e-02, -1.3678e-01,  7.3625e-02, -5.2835e-02,\n",
      "         -3.0827e-01, -6.0820e-02,  2.2263e-01,  1.3931e-02, -3.2888e-01,\n",
      "         -2.5902e-01,  1.9154e-02,  1.7650e-01, -1.8631e-01,  8.2031e-02,\n",
      "         -5.1686e-02,  3.9288e-02,  1.8848e-01, -2.1036e-03,  1.3360e-01,\n",
      "         -1.9623e-01, -8.5909e-02, -2.3922e-01, -1.7619e-02, -2.2122e-01,\n",
      "         -1.8118e-01, -1.8448e-01, -1.0783e-01, -3.2985e-02, -1.4806e-01,\n",
      "          9.7047e-02, -3.0735e-01,  1.3125e-01, -9.3430e-02, -2.6235e-01,\n",
      "          1.9898e-01,  1.5616e-01, -1.4661e-01,  2.7847e-02,  3.3748e-02,\n",
      "         -1.7061e-01, -1.6792e-01, -8.1614e-02, -3.5209e-02],\n",
      "        [-5.9225e-02,  1.5232e-01, -1.3337e-01,  2.2209e-02,  1.6783e-01,\n",
      "         -1.7880e-01, -2.3282e-01,  1.2532e-01, -7.5070e-02, -5.5016e-02,\n",
      "          1.5259e-01,  1.2005e-01,  9.8259e-02,  7.0268e-02,  1.1796e-01,\n",
      "          1.0046e-01, -2.6400e-02, -2.1939e-01,  1.3949e-01, -1.2800e-01,\n",
      "         -1.8719e-01, -1.9837e-01, -2.6289e-01, -2.0975e-01,  1.0314e-01,\n",
      "          7.1910e-02,  9.7606e-02,  5.8615e-02, -2.6664e-02,  3.0018e-02,\n",
      "         -1.9035e-01,  4.1528e-02,  2.1692e-01, -1.7562e-02,  6.5954e-02,\n",
      "          5.2602e-02, -2.7236e-01,  1.0242e-01, -6.1196e-03,  6.3889e-02,\n",
      "         -1.3810e-02,  3.5282e-02,  9.3402e-02, -1.3251e-01,  1.2507e-02,\n",
      "         -7.0189e-02, -1.2045e-01,  7.2836e-02, -2.3922e-01, -7.2715e-02,\n",
      "         -1.9233e-01, -3.6491e-02, -1.3283e-01, -1.6990e-01,  7.9744e-02,\n",
      "          1.5413e-01,  1.3338e-03, -3.1146e-01,  3.8347e-02, -5.1136e-02,\n",
      "          2.5637e-02,  1.5202e-01,  5.0993e-02, -2.6282e-01, -3.2239e-02,\n",
      "         -3.4758e-01,  4.9413e-02, -1.6952e-01, -2.1407e-01, -2.7427e-01,\n",
      "         -1.4446e-01,  9.4169e-02,  5.8996e-02, -2.0333e-01, -3.7950e-02,\n",
      "         -1.7015e-01,  1.4879e-01, -3.5829e-03,  4.1087e-02,  6.0534e-02,\n",
      "          2.8116e-02, -8.4273e-02, -1.0116e-01, -3.2503e-02],\n",
      "        [-2.9718e-03,  5.3963e-02, -1.2578e-01, -8.2539e-03, -2.3825e-01,\n",
      "         -9.5368e-02, -1.2655e-01,  2.3530e-02, -1.5298e-02, -7.0589e-02,\n",
      "          1.3161e-01,  1.2351e-01,  7.5901e-02, -5.6902e-03, -2.1397e-01,\n",
      "         -3.6949e-02, -3.8364e-02,  1.5185e-01, -6.0129e-02,  1.5749e-02,\n",
      "         -7.6165e-02,  9.8026e-03,  1.5638e-02,  8.9991e-03, -1.5320e-03,\n",
      "         -1.0122e-01,  1.0505e-01,  4.6864e-02,  1.1958e-01,  4.5770e-02,\n",
      "         -3.5767e-02,  7.7770e-02, -6.3524e-02, -1.7474e-01,  8.0299e-02,\n",
      "          1.5798e-01, -4.6281e-01,  1.8750e-01, -1.7423e-01, -1.1222e-01,\n",
      "         -2.6467e-01, -5.4367e-02, -9.6754e-02,  2.5929e-02, -8.6363e-02,\n",
      "         -1.8359e-02,  5.8339e-02, -3.1431e-01, -1.4817e-01,  9.0305e-02,\n",
      "          1.3811e-01, -1.4580e-01, -1.5226e-01,  5.1557e-02, -1.5405e-01,\n",
      "         -1.8758e-01,  7.7177e-02, -6.4230e-02,  1.4821e-01,  1.1261e-01,\n",
      "          1.1845e-01,  4.4871e-02,  7.2856e-02,  4.3763e-02, -1.6187e-01,\n",
      "          1.2553e-01, -3.0204e-02, -9.5251e-02,  1.8109e-01, -2.1170e-01,\n",
      "         -1.1219e-01, -2.2226e-01, -3.4614e-01, -1.7479e-01, -1.8233e-01,\n",
      "          1.0721e-01, -1.0242e-01, -2.4333e-01, -1.0540e-02, -7.3169e-02,\n",
      "          7.0590e-02,  2.3380e-02, -9.0666e-02,  1.2051e-01],\n",
      "        [ 6.9343e-02,  2.0513e-02, -1.8623e-01, -1.7245e-01,  1.6849e-01,\n",
      "          5.1278e-02,  1.3308e-01, -9.2926e-02,  2.1734e-01,  6.9840e-02,\n",
      "         -3.2309e-02,  5.7971e-02, -1.5281e-01, -5.5200e-02, -1.8348e-01,\n",
      "         -2.4407e-01,  2.2091e-01,  9.8739e-03,  1.3769e-01, -9.6167e-03,\n",
      "          1.1327e-01, -4.8600e-02,  9.5651e-02, -4.7902e-02, -2.6597e-02,\n",
      "          5.5357e-03,  1.2940e-02, -1.9082e-02, -1.7469e-02, -2.4394e-01,\n",
      "         -1.3230e-01, -3.5598e-01, -9.8459e-02, -1.2449e-01,  1.5446e-02,\n",
      "         -1.3049e-02, -3.7031e-01, -4.3981e-02,  2.0227e-01, -7.8465e-02,\n",
      "         -7.5275e-02,  4.5362e-02, -1.8576e-01,  4.1773e-02, -1.7083e-02,\n",
      "         -8.0088e-02, -2.5027e-03,  1.1717e-01, -3.0263e-02, -4.2385e-02,\n",
      "          1.3701e-01,  1.4658e-01,  2.9449e-02, -9.1336e-02,  2.1666e-02,\n",
      "          1.1964e-01, -1.8940e-01, -1.7313e-01, -1.7754e-01, -1.6237e-02,\n",
      "         -4.1573e-02,  7.0919e-02, -1.5110e-01, -1.7574e-01, -4.4798e-02,\n",
      "          8.8528e-02, -5.0926e-02, -1.0237e-01,  4.8905e-02, -5.6131e-02,\n",
      "          1.1641e-01,  1.4749e-01,  1.7250e-02,  1.1182e-01,  7.2963e-02,\n",
      "         -1.4167e-01,  9.3675e-02, -1.5635e-02,  9.1407e-03,  8.9237e-02,\n",
      "         -2.9254e-01,  1.2055e-01, -1.4933e-01,  1.0722e-01],\n",
      "        [-3.4550e-02,  6.8007e-02, -1.6665e-01, -3.7996e-02, -1.0238e-01,\n",
      "         -6.6724e-02,  6.5202e-02, -1.5698e-01,  1.2563e-02, -6.5477e-02,\n",
      "         -8.6807e-02,  3.0849e-02, -9.2997e-03,  1.0873e-01,  1.0403e-01,\n",
      "          1.7998e-01,  1.4297e-01, -4.6222e-03,  9.7133e-02,  1.4710e-01,\n",
      "         -2.2727e-01,  3.9038e-02, -2.6356e-01, -9.3128e-03,  6.5484e-02,\n",
      "          3.1661e-02, -2.0467e-01, -1.3224e-01, -8.3686e-02,  8.9466e-02,\n",
      "         -8.9728e-02,  7.3738e-02, -1.1172e-02, -1.9465e-01, -8.4550e-02,\n",
      "         -1.9107e-01, -1.6804e-01, -8.6172e-02,  2.2499e-02,  3.8420e-02,\n",
      "         -8.5226e-04, -1.0883e-01,  1.5381e-02, -5.1003e-02, -1.9582e-02,\n",
      "          1.0450e-01,  1.2308e-01, -2.7576e-01,  3.8710e-02,  2.7701e-02,\n",
      "          1.0126e-01, -2.7613e-01, -8.1787e-02,  8.3767e-02,  4.7730e-02,\n",
      "         -2.5021e-01,  8.2256e-02, -2.5454e-01, -1.2279e-01,  1.2099e-01,\n",
      "         -6.7231e-02,  2.8655e-02, -2.1337e-02,  1.4244e-01, -1.5317e-01,\n",
      "         -1.1692e-01,  3.7037e-02,  1.0417e-01,  9.1940e-02,  7.7262e-02,\n",
      "          1.4814e-01, -1.9946e-01, -5.7858e-02,  3.8785e-02, -2.1925e-01,\n",
      "         -1.8307e-03,  1.7900e-02,  2.0247e-01,  5.4257e-02, -1.4604e-01,\n",
      "          1.1259e-01, -1.3372e-01, -4.0541e-02,  9.8532e-02],\n",
      "        [-3.8523e-01, -2.4726e-01, -1.0273e-01,  6.6036e-02,  1.0415e-01,\n",
      "         -1.0954e-01, -2.1390e-01, -9.0150e-02, -1.6217e-02,  5.1434e-02,\n",
      "          1.0850e-01, -1.0726e-01, -1.3952e-01, -1.5579e-01,  1.4786e-01,\n",
      "          3.3502e-02,  1.1256e-01, -1.6151e-01, -1.1368e-01, -2.3840e-02,\n",
      "          1.2829e-01, -2.7688e-01,  1.0475e-01, -8.9281e-02,  3.8371e-02,\n",
      "          9.2902e-02, -2.2792e-01, -3.5642e-02, -1.4664e-01, -6.9095e-02,\n",
      "         -7.1701e-02,  7.5376e-02, -1.1184e-01, -2.4983e-02, -7.3091e-02,\n",
      "          1.2024e-02,  4.6248e-02,  2.2569e-02,  6.1299e-02, -7.0995e-02,\n",
      "         -4.7037e-02,  7.2172e-02, -2.2932e-02,  2.6033e-02, -4.7235e-02,\n",
      "          1.3009e-02,  3.6236e-02, -7.1003e-02,  1.2548e-01, -1.5794e-01,\n",
      "          7.6343e-02, -2.0160e-01,  8.2735e-02, -1.1917e-01,  7.7113e-02,\n",
      "          5.5854e-03, -2.1516e-01,  1.6217e-01, -2.8420e-01, -2.9271e-01,\n",
      "         -2.3189e-02,  4.6627e-02,  9.3642e-02,  1.5668e-01, -5.3361e-02,\n",
      "         -2.0736e-01, -4.3840e-02,  7.1199e-02, -1.7074e-01,  2.0135e-01,\n",
      "          1.6863e-01, -1.6062e-01,  3.1019e-02,  8.5683e-02, -1.6374e-01,\n",
      "          1.3853e-01, -1.6137e-01, -1.4675e-01, -4.5572e-02, -1.7870e-01,\n",
      "          7.3326e-02, -5.2192e-02,  6.5291e-02, -9.8535e-02],\n",
      "        [ 4.6848e-02,  1.6534e-01,  8.4541e-02,  1.8911e-02, -3.3711e-01,\n",
      "         -1.2722e-01, -1.6140e-01,  6.2259e-02, -2.7663e-02, -9.2934e-03,\n",
      "          1.6694e-01, -8.7203e-02, -6.0969e-02, -1.2099e-01, -1.4954e-01,\n",
      "          4.9336e-02,  3.2240e-02, -2.8299e-02, -1.0664e-01,  2.1664e-01,\n",
      "          1.9980e-01, -3.0359e-02, -8.0042e-02, -2.8368e-02, -1.7025e-01,\n",
      "         -1.4655e-01,  5.3464e-03,  1.7033e-01,  4.5071e-02,  1.4203e-01,\n",
      "         -1.1841e-01, -1.9070e-01,  1.3637e-01,  2.8260e-02, -5.8166e-02,\n",
      "         -1.8169e-01, -4.4658e-01, -1.3960e-01, -7.0853e-02,  5.3249e-02,\n",
      "          2.3040e-01, -9.2160e-03, -2.5058e-02,  5.2544e-02, -5.8932e-02,\n",
      "          1.1401e-01,  1.2750e-01,  2.1218e-02, -1.5431e-01,  7.1972e-02,\n",
      "         -1.7780e-01,  1.3794e-01,  1.6287e-01, -4.7815e-02, -1.9082e-01,\n",
      "         -2.3450e-01,  1.6496e-01, -2.2408e-01, -6.6880e-03, -9.6821e-02,\n",
      "          2.2637e-02,  6.5793e-02, -2.4899e-01, -7.0064e-02, -1.6361e-02,\n",
      "          2.0875e-02,  9.1139e-03, -2.5441e-01,  1.8475e-02, -2.9046e-01,\n",
      "         -2.1080e-01,  1.2463e-01, -1.4392e-01,  6.5449e-03, -1.0346e-02,\n",
      "         -1.2566e-02, -1.9677e-01,  1.3293e-01,  4.3929e-02,  1.7759e-01,\n",
      "         -5.3035e-02, -1.4949e-01, -1.1160e-01, -1.0427e-01],\n",
      "        [-9.0451e-02,  1.5027e-01,  6.4232e-02, -2.7485e-01,  2.0734e-02,\n",
      "         -1.9703e-01,  6.8300e-02,  1.2981e-01, -1.4917e-01, -9.8701e-03,\n",
      "         -1.1041e-01, -5.4005e-02,  1.0810e-01, -3.2541e-01, -2.6574e-02,\n",
      "         -6.5352e-02, -1.4740e-01, -1.4012e-01,  7.7777e-02, -1.3736e-02,\n",
      "         -1.3562e-01, -3.3372e-02, -2.5865e-01,  6.5360e-02, -7.2031e-02,\n",
      "          4.6254e-02, -1.8046e-01, -3.1164e-01,  1.7402e-02, -4.2096e-02,\n",
      "         -3.0204e-02,  1.3915e-01, -3.1817e-01, -1.0168e-01,  3.7260e-02,\n",
      "          1.9538e-01, -3.8807e-01, -5.8647e-02,  5.2416e-02,  1.0819e-01,\n",
      "         -8.6668e-02, -1.5013e-02, -4.9672e-02, -1.1632e-02, -5.3408e-02,\n",
      "         -4.7558e-02, -1.2159e-01,  8.5485e-03,  1.2699e-01, -1.3148e-01,\n",
      "         -4.4978e-02,  1.4195e-02,  1.5728e-01,  9.4735e-02, -1.1350e-02,\n",
      "         -2.5765e-01, -2.6343e-02, -3.8405e-01,  1.1401e-01, -1.1959e-01,\n",
      "          9.8198e-02,  9.4962e-03,  8.2447e-02, -5.9929e-02, -1.6528e-01,\n",
      "          2.0733e-01,  1.3260e-01,  1.4213e-01,  1.1493e-01,  1.8960e-01,\n",
      "         -1.7576e-02, -7.5516e-02,  1.4669e-01, -1.3960e-01,  4.8645e-02,\n",
      "          7.7525e-02,  6.2691e-02, -2.9345e-01,  7.9528e-02, -3.6171e-01,\n",
      "          9.3994e-02, -1.6620e-01, -1.4018e-01,  8.9605e-02],\n",
      "        [-5.7974e-02, -1.0721e-01,  6.7412e-02,  1.0177e-01,  1.6469e-01,\n",
      "          1.8593e-01,  1.7993e-01, -1.1698e-01, -2.3037e-01,  2.1750e-02,\n",
      "         -3.6248e-01, -1.3181e-01, -1.7683e-01, -1.4604e-02,  6.8725e-03,\n",
      "         -1.5653e-01, -2.1997e-01, -1.4867e-02,  1.7526e-01, -1.3822e-01,\n",
      "          2.3922e-02,  1.5301e-01,  7.7314e-03,  3.9022e-02, -4.9312e-03,\n",
      "          5.5011e-02,  5.3086e-02, -7.3580e-02, -1.5210e-02, -6.9103e-02,\n",
      "          2.1841e-01, -1.6817e-01, -1.0016e-01, -3.2285e-04,  5.2286e-02,\n",
      "          3.9788e-02, -9.7193e-02, -2.4434e-01, -1.9318e-01, -2.4139e-01,\n",
      "         -3.4333e-02,  2.8640e-02, -1.9581e-01, -1.5484e-02, -8.0752e-02,\n",
      "          2.6461e-03,  1.0584e-01,  8.0790e-02,  1.6858e-01, -2.1946e-02,\n",
      "         -1.1797e-01,  1.4013e-01, -2.6532e-02,  5.3280e-02, -1.4247e-01,\n",
      "         -2.4616e-02,  1.2995e-01,  3.5376e-02, -4.8940e-02,  1.0501e-01,\n",
      "          2.7521e-02,  4.7685e-02, -1.2460e-01, -6.6235e-03, -2.4064e-02,\n",
      "         -2.4739e-02,  2.7910e-02,  1.0917e-01,  4.8659e-03, -1.2032e-01,\n",
      "         -1.9058e-01,  1.2402e-01, -1.2700e-01, -8.0076e-02,  1.2960e-01,\n",
      "         -2.7425e-01, -1.5118e-02,  7.5618e-02, -9.2758e-03,  1.0554e-02,\n",
      "         -1.4182e-01,  1.5568e-02, -1.9461e-01,  6.4240e-02]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.load('mnist_lenet5.pt')\n",
    "print(model.load_state_dict)\n",
    "print(model.fc3.weight)\n",
    "# print(30*\"*\"+\" total \" + 30*\"*\")\n",
    "# print(model.load_state_dict)\n",
    "# print(30*\"*\"+\" conv1 \" + 30*\"*\")\n",
    "# print(model.conv1.weight.size())\n",
    "# print(model.conv1.weight)\n",
    "# print(model.conv1.bias.size())\n",
    "# print(30*\"*\"+\" conv2 \" + 30*\"*\")\n",
    "# print(model.conv2.weight.size())\n",
    "# print(model.conv2.bias.size())\n",
    "# print(30*\"*\"+\" fc1 \" + 30*\"*\")\n",
    "# print(model.fc1.weight.size())\n",
    "# print(model.fc1.bias.size())\n",
    "# print(30*\"*\"+\" fc2 \" + 30*\"*\")\n",
    "# print(model.fc2.weight.size())\n",
    "# print(model.fc2.bias.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Record_Tensor(tensor,name):\n",
    "\tprint (\"Recording tensor \"+name+\" ...\")\n",
    "\tf = open('./record/mnist_lenet5/'+name+'.dat', 'w')\n",
    "\tarray=tensor.cpu().detach().numpy();\n",
    "\t#print (\"The range: [\"+str(np.min(array))+\":\"+str(np.max(array))+\"]\")\n",
    "\tprint(\"shape:{}\".format(np.shape(array)))\n",
    "\tif(np.size(np.shape(array))==1):\n",
    "\t\tRecord_Array1D(array,name,f)\n",
    "\telse:\n",
    "\t\tif(np.size(np.shape(array))==2):\n",
    "\t\t\tRecord_Array2D(array,name,f)\n",
    "\t\telse:\n",
    "\t\t\tif(np.size(np.shape(array))==3):\n",
    "\t\t\t\tRecord_Array3D(array,name,f)\n",
    "\t\t\telse:\n",
    "\t\t\t\tRecord_Array4D(array,name,f)\n",
    "\tf.close();\n",
    "\n",
    "def Record_Array1D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tf.write(str(array[i])+\"\\n\");\n",
    "\n",
    "def Record_Array2D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tfor j in range(np.shape(array)[1]):\n",
    "\t\t\tf.write(str(array[i][j])+\"\\n\");\n",
    "\n",
    "def Record_Array3D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tfor j in range(np.shape(array)[1]):\n",
    "\t\t\tfor k in range(np.shape(array)[2]):\n",
    "\t\t\t\tf.write(str(array[i][j][k])+\"\\n\");\n",
    "\n",
    "def Record_Array4D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tfor j in range(np.shape(array)[1]):\n",
    "\t\t\tfor k in range(np.shape(array)[2]):\n",
    "\t\t\t\tfor l in range(np.shape(array)[3]):\n",
    "\t\t\t\t\tf.write(str(array[i][j][k][l])+\"\\n\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording tensor W_conv1 ...\n",
      "shape:(6, 1, 5, 5)\n",
      "Recording tensor b_conv1 ...\n",
      "shape:(6,)\n",
      "Recording tensor W_conv2 ...\n",
      "shape:(16, 6, 5, 5)\n",
      "Recording tensor b_conv2 ...\n",
      "shape:(16,)\n",
      "Recording tensor W_fc1 ...\n",
      "shape:(120, 400)\n",
      "Recording tensor b_fc1 ...\n",
      "shape:(120,)\n",
      "Recording tensor W_fc2 ...\n",
      "shape:(84, 120)\n",
      "Recording tensor b_fc2 ...\n",
      "shape:(84,)\n",
      "Recording tensor W_fc3 ...\n",
      "shape:(10, 84)\n",
      "Recording tensor b_fc3 ...\n",
      "shape:(10,)\n"
     ]
    }
   ],
   "source": [
    "Record_Tensor(model.conv1.weight,\"W_conv1\")\n",
    "Record_Tensor(model.conv1.bias,\"b_conv1\")\n",
    "Record_Tensor(model.conv2.weight,\"W_conv2\")\n",
    "Record_Tensor(model.conv2.bias,\"b_conv2\")\n",
    "Record_Tensor(model.fc1.weight,\"W_fc1\")\n",
    "Record_Tensor(model.fc1.bias,\"b_fc1\")\n",
    "Record_Tensor(model.fc2.weight,\"W_fc2\")\n",
    "Record_Tensor(model.fc2.bias,\"b_fc2\")\n",
    "Record_Tensor(model.fc3.weight,\"W_fc3\")\n",
    "Record_Tensor(model.fc3.bias,\"b_fc3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
